# Analysis of Census Income data using Machine-learning analysis
## 1.Introduction
<sub> Every nation around the world face imbalance between the wealth and income. United States is one among those nations. One of the best solutions to maintain economic imbalance is by eradicating poverty in nations. This helps the nations to develop and improvise the economic imbalance. It is important for all the countries to find a best and optimal solution to control this problem. The main aim of this project is not only to make the poor substantial but also identify the predominant features essential to improve one’s income. To address the economical imbalance, machine learning and data mining techniques are performed on UCI adult dataset. This project addresses the global problem and provides optimal solutions by performing the following the analysis on the data set: data cleaning, Explanatory Data Analysis, Hypothesis Development, Data Analysis, Machine Learning, and Data visualization. This proposed project, helps me to implement all the necessary analysis discussed above that are required for a successful completion of data science project and helps find a solution for global problem. Hence, this project is a best fit for me to finish my study in data science. I want to learn more about ANOVA, Machine Learning algorithms and Data Visualizations using tableau. The initial phase of the project includes Data Collection, Data Cleaning and Explanatory Data Analysis. In the second phase, hypothesis are developed, data visualization using tableau and machine learning models are performed. The literature section below discuses about the existing state of the artwork that is comparable to the study of research suggested in the paper. </sub>
## 2.Statement of Problem
<sub> The UCI Adult dataset is used to eradicate the imbalance between wealth and income. This is done by performing classification on a set of attributes to anticipate if an individual’s annual income in the United States fits into the income segments of greater than 50k Dollars or less than or equal to 50k Dollars. It also helps us determine the features or attributes that makes a person to have earn less by developing few hypothesis. These features can be used as areas to improvement by the government to address the global problem.   This study applies all the phases (data collection, data preparation, Explanatory Data Analysis, Modeling, Machine learning models, Model Evaluation and interpreting the results) of a data science project to obtain the results for the described research question. The research aims to find a solution for a global problem faced by many nations’ government.  </sub>
<pre>
## 3.Related Work
###3.1. Purpose of Study
<sub>In this paper, the author predicted the income build on population survey done by U.S. Census Bureau. Super Vector Machines and Principal component analysis are used to perform the analysis. The paper also concentrates on how to improve the efficiency and accuracy of model by selecting the appropriate feature. In this process grid parameter search, training time, accuracy and number of super vectors are considered as suitable features for the study. This paper talks about data preprocessing, SVM, PCA, Comparing the accuracy between the subsets which can be implemented on my dataset to predict the income levels. I intend to work on SVM algorithm for my research project and this paper has motivated me to apply the SVM algorithm on my dataset. (Alina, 2004) </sub>
###3.1.2. Related Literature 
<sub>The Key concepts involved in the paper are Super vector Machines, Principal component Analysis, Data Preprocessing, SVM Grid Search, accuracy, ROC curve. This paper has reviews 16 articles.</sub>
###3.1.3. Research Design
<sub>The dataset used in this paper is the population survey data from U.S. Census Bureau. It contains data about social, demographic, other characteristics of work force that is 16 years old and records the details of employment, unemployment, and income. Due to the huge size of the data, this study used many data mining methods like neural networks, KNN, decision tree and SVM. In this paper the features of SVM and PCA are discussed. The Super vector machine follows two steps: uses a series of related functions called Kernel and hyperplane learning algorithm is implemented on the kernel. The dataset will be split into training and test data before applying SVM algorithm on the dataset. Gaussian Kernel can be used with SVM to train the dataset systematically by using Cross validation on the train dataset and implement Grid search. PCA is an approach that is used to divide the large dataset into small dataset using the independent variables. The results of these smaller sets will be like the results of larger sets because the smaller sets are the subsets of the larger sets. PCA uses Eigen vectors and Eigen values to obtain the principal components i.e., smaller sets. 
There is a life cycle that needs to be followed for completion of a data science research. One of the important phases is data preprocessing. Data Preprocessing should be applied on the dataset to remove the noisy data from the dataset. This phase should be implemented before executing the machine learning algorithms on the dataset. </sub>
###3.1.4. Conclusion
<sub>To conclude, the huge dataset was divided into six subsets and the classification conclusions for SVM and PCA are showcased in the paper. The above six subsets are used to compare the performance and training time of SVM algorithm. All the six datasets are classified based on accuracy and ROC. The ROC graphs consists of classification rate and the number of false positive rate. To reduce the dataset with large independent values PCA is used. The classification error rate for algorithms is predicted. In future, this study can be extended by using Kernel PCA method for improving the classification error rate.</sub>
###3.2. Purpose of Study
<sub>The Two-class Boosted Decision Tree algorithm will be used in this study to determine if a person's annual income is over or below $50,000 based on census data. To review and analyze the data, the author used a machine learning technology. The program predicts a person's income based on a variety of criteria from the dataset. Finally, the paper seeks to evaluate whether persons with more education earn more money. This paper talks about steps of machine learning, what factors are important to gain higher income and Two-Class Boosted Decision Tree which can be implemented on my dataset to predict the income levels. I intend to work on supervised algorithms for my research project and this paper has motivated me to apply supervised algorithms on my dataset. (Victor, 2016) </sub>
###3.2.1. Related Literature 
<sub>The key concepts covered in the paper are Machine Learning, Two-class boosted decision tree, predictive analysis, supervised learning, unsupervised learning. This paper has reviewed 3 papers to attain the purpose of the study.</sub>
###3.2.2. Research Design or Strategy
<sub>There are few steps that machine process follows to obtain solution for a research question in no time. The steps include data collection, creating a model, evaluating the model, refining the model, deploying the model, and testing the final model. Microsoft Azure Machine Learning studio is used to analyze a solution for the research question. Machine Learning algorithms are classified into three different algorithms: Classification, regression, and Clustering algorithms. Classification algorithms are used to predict data based on discrete variables which regression and clustering are used to predict data on continuous, grouping data for a given variable. Supervised and Unsupervised are the two types in machine learning. Classification and Regression algorithm fall under supervised machine learning techniques and cluster analysis falls under unsupervised learning algorithms.
Two-Class Boosted Decision tree is an algorithm which is centered on boosted decision trees. In boosted decision trees, the mistakes of first trees are rectified by second trees and the mistakes of first and second trees are rectified by third trees. The predictions are made based on the correction of all the trees. Irrespective of predicting the results collaboratively by all the trees, the boosted decision trees accumulates more memory and is not suggestable for analyzing huge datasets. Before applying the algorithm on dataset, the data is split into train and test (80% and 20% respectively).</sub>
###3.2.3. Results and Conclusion
<sub>Machine Learning is the best technique to make predictions from many variables. For the above research the author used machine to predict if education one of the important factors to obtain a better income. The graphs are plotted between false positive rate Vs true positive rate, Precision Vs Recall, and no. of true positives Vs Positive rate to conclude which features are deciding factors for high income. According to the results, education and occupation have a major contribution for obtaining high income.</sub>
###3.3. Purpose of Study
<sub>This paper uses an unsupervised machine learning classification algorithm. The classification algorithms forecast the value of a categorical variable based on other variables in a dataset. This paper showcases various classification algorithms like decision tree, Bayesian networks, lazy classifier, and rule-based classifier. These algorithms are implemented on the adult data set. The author in this paper tries to compare various classification models like naïve Bayesian, Random Forest, Zero R, K star based on accuracy. This paper is a close match to my research topic because, I will work on various classification models to find the best model for my dataset. (Deepajothi & Selvarajan, 2012) </sub>
###3.3.1. Related Literature
</sub>The Key concepts covered in the paper are Data mining, Bayesian classification technique, Random Forest, Decision Tree, Rule Based Classifiers, Lazy Classifiers. This paper has reviewed 15 papers to attain the purpose of the study.</sub>
###3.3.2. Research Design or Strategy
<sub>Data Mining includes data analysis tools to perform analysis on the large data sets. There are various criterions to analyze the data. The criterions include association, sequence, classification, clustering, and forecasting. The classification techniques used in the paper are Bayesian network, tree classifiers, rule-based classifiers, Lazy classifiers, Fuzzy set approaches and rough set approach. While performing classification on the dataset, two steps should be taken into consideration model construction and model usage. The classification is based group of classes and model construction is about predetermined classes and model usage is for dividing future or unknown objects. Bayesian Classifiers analyze probabilities of a class and are used to possess high accuracy for large datasets. Decision Tree induction is derived from decision trees. Decision tress are the tree structure which consists of class labels. A Decision tree is comprised of three components internal node used for testing an attribute, branch the interprets the outcome and leaf node used for class label.  For this study, Random Forest is the decision tree induction method applied on the dataset. Random Forest is a combination of multiple decision trees whose output is the combination of classes obtained from all the trees. Rule-Based algorithms anticipate set of rules that can be used as predefined rules for classify classes. Unlike all the classifiers, Lazy classifier construct a classifier only when the new class needs to be classified. It is easy but slow when comes to other classifying models. </sub>
###3.3.3. Conclusion
<sub>Out of all the above algorithms suggested in the paper, Naïve Bayesian is the best algorithm for the adult dataset. Zero R, Random Star and K star are subsequently used after Naïve Bayesian and fall in the same range. This algorithm is easy and efficient with high accuracy compared to all the other algorithms applied on the dataset.<sub>
###3.4. Purpose of Study
<sub>The purpose of the study is to analyze the earnings of a bank’s customers. To predict the incomes, the author used numerous regression algorithms like ordinary least squares regression, MARS, ANN, LS-SVM and CART are implemented on five different datasets. To evaluate the performance of the model, many techniques such as R2 curve, hit rate, precession, recall etc. are used in this paper. I intend to implement different regression algorithms on my dataset. This paper helped me understand about the various regression algorithms (Kibekbaev & Duman, 2015). </sub>
###3.4.1. Related Literature
<sub>The Key concepts used in the study are Regression Techniques, Performance measures, RMSE, MAE etc. This paper has reviewed 19 articles to attain the purpose of the study.</sub>
###3.4.2. Research Design or Strategy
<sub>The aim of the research is to predict the income for a customer in a bank due to imposition of strict rules in the Turkish banks. The rule states that “Customer credit card limit cannot exceed 4 times the amount of monthly income.” Therefore, to identify a model that predicts accurate income for a person is critical. To identify the accurate income of a person and calculate the single limit for a person, regression analysis can be used by evaluating the relationship between dependent and independent variables. Linear and nonlinear are the two types of regression analysis and is segregated into one-stage and two-stage. The performance measures used in the paper are RMSE, MAE, AUC, AOC, RSquare, Pearson’s R, Spearman’s P, Kendall’s , Hit rate and preciseness.
Before applying the regression analysis on the 5 datasets. The data preprocessing should be performed on the data. After the preprocessing, the data is split into 70% train and 30% test. Variable selection is performed based on two criteria cost and performance to select the appropriate features. The variables in the dataset are similar therefore stepwise selection which is a technique with both backward elimination and forward selection is used.  After applying all the models on the data set, hit rate, R square and preciseness are used as a metrics for performance evaluation. </sub>
###3.4.3. Conclusion
<sub> After applying the 16 regression techniques and 10 various performance metrics on the dataset. The non-linear and two stage techniques are best algorithm techniques for Turkish banks datasets based on the results of performance metrics. For improving this paper further, the same experiment can be carried out on self-employment or retirement datasets.</sub>
###3.5. Purpose of Study
<sub>This paper aims to analyze the salary plans of employees based on the performance. This can be done by considering certain information like performance level, qualification etc., the income class can be predicted by machine learning algorithms. Collecting this personal information was difficult. Therefore, a UCI public database was used that contain similar attributes required to predict the income. This paper uses supervised algorithms like Gaussian Naïve Bayes, Gradient Boosting Classifier, Support Vector Machine, Random Forest Classifier and Decision Tree to identify the best classifier for the dataset. This paper is the best match for my research study because the algorithms used in the study are the algorithms that will be used to answer my research question (Bramesh & Puttaswamy, 2019). </sub>
###3.5.1. Related Literature  
<sub>The Key concepts in the paper are Machine Learning, Decision Tree, Gaussian Naïve Bayes, Gradient Boosting, Random Forest, and Super Vector Machines. This article has reviewed 13 papers to attain the purpose of the paper.</sub>
###3.5.2. Research Design
<sub>For continuous success in the organizations, it is important identify the salary plans for excellent performing employees and to withhold the talented people in the organization. It is the responsibility of the HR department to determine salary to the current or future employees based on several aspects like qualification, previous performance, experience etc. Therefore, to predict the salary for current and future employees machine learning algorithms like Gaussian Naïve Bayes, Gradient Boosting classifier, Support Vector Classifier, Random Forest Classifier, and Decision Tree. To achieve the accuracy in prediction of salary class based on certain features, the above discussed machine learning are implemented on the UCI adult dataset and the performance of each model is contrasted based on accuracy, Roc and F-measure. 
EDA is performed on the dataset, and it is found that there are six continuous attributes, nine categorical variables and one target variable that is dependent. Based on the binary classification, he target variable is divided into two classes. The Correlation matrix is used to describe the relationship between continuous and target variable. After identifying the relationship, Machine learning algorithms are applied on the dataset using Python’s Scikit-Learn Machine Learning Toolbox and Python’s plotting libraries like matplotlib and seaborn for data visualizations.</sub>
###3.5.3. Conclusion
<sub>To sum it all, the five machine learning algorithms like Gradient Boosting classifier, Gaussian Naïve Bayes, Support Vector Machine, Decision Tree and Random Forest are applied on the dataset to figure out which algorithm gives the best results to predict the accuracy in salary class. Gradient Boosting Classifier is the best classifier with highest ROC, high accuracy, and low misclassification rate. This study can be extended by using the more recent census data to predict the salary class for today’s population as the data used in this paper is quite old.</sub>
 </pre>

  
